{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyPkEVXQL3iqI2nXHOQfByYP"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZsmNyMPJfDCA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762806273795,
     "user_tz": 480,
     "elapsed": 36767,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "fda0efe0-9869-48d3-abb2-756b14ee2a55"
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers==4.55.2 datasets==4.3.0 peft==0.11.1 accelerate==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 移除會卡 pyarrow 版本的 RAPIDS 套件（不存在也沒關係）\n",
    "!pip uninstall -y cudf-cu12 pylibcudf-cu12 dask-cudf-cu12 cuml-cu12 cugraph-cu12 bigframes || true\n",
    "\n",
    "# 也順手移掉以前殘留（可選）\n",
    "!pip uninstall -y gcsfs fsspec pyarrow || true\n",
    "\n",
    "# 升級 pip\n",
    "!pip install -U pip"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2_fg8VWds1-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762806667674,
     "user_tz": 480,
     "elapsed": 15700,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "06b766ae-131b-402e-f436-51aa1d61b423"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# datasets 4.3.0 需要 pyarrow>=21；用 21.0.0 穩定、不和 RAPIDS 打架\n",
    "!pip install \"pyarrow==21.0.0\" \"fsspec==2024.5.0\" \"gcsfs==2024.5.0\"\n",
    "\n",
    "# LoRA（CPU）最小組合\n",
    "!pip install \"transformers==4.55.2\" \"datasets==4.3.0\" \"peft==0.11.1\" \"accelerate==1.4.0\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CeVsrJ_5d5MR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762806716891,
     "user_tz": 480,
     "elapsed": 15579,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "cf258c6b-f792-4fff-d3fa-988e08c3a6d6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import transformers, datasets, peft, accelerate, pyarrow\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"peft:\", peft.__version__)\n",
    "print(\"accelerate:\", accelerate.__version__)\n",
    "import pyarrow as pa; print(\"pyarrow:\", pa.__version__)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqVQamtAd_Zu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762806768917,
     "user_tz": 480,
     "elapsed": 42095,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "da61df85-96d9-4ec6-f8be-094dc8c3d452"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 1) 建立資料夾 + 寫入最小訓練集（你可自行替換為自己的資料）\n",
    "import os, json\n",
    "os.makedirs(\"/content/data\", exist_ok=True)\n",
    "\n",
    "samples = [\n",
    "    {\"instruction\":\"You are a helpful assistant. Answer briefly.\",\n",
    "     \"input\":\"What is overfitting in machine learning?\",\n",
    "     \"output\":\"Overfitting means the model memorizes training noise and fails on new data.\"},\n",
    "    {\"instruction\":\"You are a helpful assistant. Answer briefly.\",\n",
    "     \"input\":\"Explain cross-validation in one sentence.\",\n",
    "     \"output\":\"It splits data into folds to estimate generalization performance.\"},\n",
    "    {\"instruction\":\"You are a helpful assistant. Answer briefly.\",\n",
    "     \"input\":\"Give a short tip to avoid overfitting.\",\n",
    "     \"output\":\"Use more data, regularization, and early stopping.\"}\n",
    "]\n",
    "with open(\"/content/data/chat_train.jsonl\",\"w\") as f:\n",
    "    for ex in samples:\n",
    "        f.write(json.dumps(ex, ensure_ascii=False)+\"\\n\")\n",
    "\n",
    "# 2) 驗證檔案存在\n",
    "import os\n",
    "print(\"exists:\", os.path.exists(\"/content/data/chat_train.jsonl\"))\n",
    "!head -n 2 /content/data/chat_train.jsonl"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MTuWZU5gMOy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762807304934,
     "user_tz": 480,
     "elapsed": 108,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "8703481a-3f53-45cf-ba13-b6157b2d03cd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"json\", data_files={\"train\": \"/content/data/chat_train.jsonl\"})\n",
    "train_ds = ds[\"train\"]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "42abab1d45db47108ad1d7cc52d56af9",
      "a1ef65ae0b52493685b241bc47cb581b",
      "5386002a5e3242ad9aa86104e71d004f",
      "dff70b520cd84a32b55357ad89595157",
      "25adf2ffe3394eb6ae9f16e6f27e7337",
      "47c6cbee30084d0aa3378f531abfd4d3",
      "1b54dd50486d49a6ac3cb11437eb3e17",
      "21f8e57a78be4f3cbb8ce3cec35435f9",
      "6c4c3b482e9a4c3aa6b9ce97becf9e41",
      "5563e6a61e314d1ba24415f07fc8dfc8",
      "7bf4de65f19d41e2a61270899dcb8b0b"
     ]
    },
    "id": "RoJ1QWSFgO-3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762807315165,
     "user_tz": 480,
     "elapsed": 293,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "7c3d59e5-8936-483c-d1e4-f872ae9c9098"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"json\", data_files={\"train\": \"/content/data/chat_train.jsonl\"})\n",
    "train_ds = ds[\"train\"]\n",
    "\n",
    "# 轉成簡單的指令格式文字\n",
    "def to_text(ex):\n",
    "    return {\"text\": f\"### Instruction:\\n{ex['instruction']}\\n\\n### Input:\\n{ex['input']}\\n\\n### Response:\\n{ex['output']}\"}\n",
    "train_ds = train_ds.map(to_text, remove_columns=train_ds.column_names)\n",
    "print(train_ds[0][\"text\"][:200])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192,
     "referenced_widgets": [
      "884bf1406cea4ea48d32bc6ac6134550",
      "3798016f2e364c07830c1a1198fc0c43",
      "fb9697c7f83544958a5a3be40777d3ff",
      "13da1c0adbec495c8e88c29f605594cb",
      "a870176aefee42519741c0c73d11dcfd",
      "31866e5e3769404ba734c3a547953693",
      "a246a9d7a2ef43a4b1bae50556ec8ec7",
      "44a348860bdc4227ba7ad9df36ed7466",
      "13e2c80c80a54c479cfae40a3746174b",
      "3d29b1661a0d40cbb983975a0bc9ddec",
      "c1cebc048ae44ad9a123ca8e91e1ab6a"
     ]
    },
    "id": "cXuXgN3kgdRW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762807373639,
     "user_tz": 480,
     "elapsed": 105,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "13aefbdb-9531-4263-cff0-b64fdd129b78"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch, os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_num_threads(2)              # 視你的 CPU core 可調高；越高越快但也更吃資源\n",
    "MODEL_NAME = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float32,        # CPU 用 FP32 最穩\n",
    "    device_map={\"\": \"cpu\"},           # 明確指定 CPU\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400,
     "referenced_widgets": [
      "edc7d370a5b54c7c8a438320b1a73d37",
      "a735e321c21245989d702dbc3319487c",
      "30cd542e9d0b4263b0aea89a83c65c09",
      "c5fe4ef20e8249c5ab3c16b636a214d6",
      "9af8598b55e240b8856257062750678f",
      "4bcd383f2b504300a37129fe66b4831e",
      "2382ba72a7bd4dcb827415ccfe7e5ac9",
      "11b08c32fa3f45cbad230b6ca40c2a43",
      "042a4ede0b524633985ad53fa28f87d9",
      "e818b7de1f084838ab3c87c504e45991",
      "f8f9f06090de4135b50b895d3ea8d7a3",
      "f1b619a361424e9fa3e574825e95450f",
      "534685d9a9874a419f4171949dad319c",
      "1c9e52d25d124cda9c9c0375f35f9995",
      "def3d74826504cdd8a9bfb6e1cab537d",
      "8be362e7bf64455a917b12a6a3f7136c",
      "896527b37f934ace89c0dfd0c50b9812",
      "4853519642b64cae84baacb3c1e28c09",
      "d633b9945092422d8f01bac2c661d715",
      "98194129dd9c4ad59b4128854f5a0dac",
      "a5765b4e698d4155bc4c4cbaf5678ed2",
      "a94f6b91943a4490a55b8e6bc45e1d3e",
      "121d4c9d61494c53bad1ba662a6efaff",
      "c5191863278b4f628d513a8b0a2d2216",
      "c6f519b89cff4ea89516bafd9a0587a9",
      "e7df6c72124445c089a05928aac1e820",
      "d28d90084a044a3ba8c7bcf158fbf9a1",
      "0341edf1121e42f48254e995c395f3e9",
      "41decc0c09ab44e2abb3a313ac838abf",
      "8b39a620022b45eabe9d7122b73f0b9c",
      "2c6e7f6fafd3429fa593639f83615c6c",
      "25bf96ae573544d8a19f00aac0c5da76",
      "b22676e35d2a42748095b5c571c62707",
      "7d66ca979e664c738e28cb193b4e651f",
      "948ccd8374e3492d8db997ccdcc61d38",
      "cd0db711a795437799bc163061a47004",
      "59f5ce7bbf6a4d50b10637507a9b2d54",
      "b9accf70cc5740959e9b74717ea31f5a",
      "6ceb8dca2fbd47ebb7b0a597e5c5bf17",
      "ebbdaaf642bc41b181f22abf01d4b964",
      "381090503e3d4381b3dfbf397d822df7",
      "a45443787b0c41729e838e8ee19d4de6",
      "14e5766151ae43beb8d7c26906736f41",
      "b4bcee78ea374139ba1afa432d8e8659",
      "eced212a3efd4994833444806dd8ecec",
      "776c229cd85c4331b9b86a0a77e6e917",
      "291cd3939b1c466284d5a6a5aa2c2306",
      "ac169e29cd0d410ea4c3eea8004f9054",
      "1d76b9021d9349d588087731d7672381",
      "c7e356b23a244f08af3922d066a7d7fa",
      "3f985175f905465a9ea8dbf0fd17e1cc",
      "6cc82a4692bb4ff49ded3441f0869c7e",
      "2cf8ae7d3bc0443a8ebf09644a5f50d5",
      "b5a14837dedc408faf7ef7c4ec076014",
      "8410791125174032b5db971985d2495b",
      "0e69d5e5ff38437395fd1a404ef38bd7",
      "2c248b2caa224d0ab43d19ae5342e4b8",
      "76a374f744ea4ce6a270e92703468979",
      "2e9b016396ae43d59e1f940dc245e2b8",
      "f36a7f08a14b495f86c88d23807b3aa8",
      "14d3edf31e2642f0914dcb90ea7d0d2e",
      "f0e025f0219243dd8fb7926d99355a6b",
      "d42363018b8f4e4a862c9e57ad3fb048",
      "1d45da0ef5a54c29bfce63f3d896e150",
      "7a30f1ec1cc44a248da7d1c375eecde2",
      "fa3fc43956d64adea26c0cf7b9b87653",
      "f14eaf9e33574802bbe0ae8e9130b183",
      "b30e071672ad404cacc36f1be357dd00",
      "468943e6fa7d4214b4bcfd1e2a163713",
      "4b96d06d08a4417a93f782dc7e855b3c",
      "9552237810094dce8071aecdd636c030",
      "ef57618d9e5845f08695c29f38c3ac55",
      "d596bd06f8954023be4723973a79b638",
      "aee0351e02e64068a006492a7fa87cb7",
      "971a74369ebb438b909b83f75c2ac099",
      "f0b3525e078f4536a6cb937b95084318",
      "371d49ac86144918852b08953d61ced8",
      "3132ec8b0fd947909869b164fc3aa476",
      "789b4598374e4e3a8aaa2e01a9fe718f",
      "e46c74f42b4b4cffa6392302b3033f48",
      "c5bb5467de824f8ea112ce29fe66d057",
      "e842c8726af647fc8fb77486b69cc4ff",
      "d754b2ebc35a4754b3bb7ccb23279075",
      "e13c2174541e4d7494fdd063eee16da5",
      "63ec1faa364b40d18fe7988154f59b69",
      "a8954e02ccbb408a9e5518646bfb34e0",
      "c1bf96d7ef3c48d4a5960b572e45d91c",
      "91fe1f3a257143aebb47095fcdd78107"
     ]
    },
    "id": "cdSGlJQNgh0t",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762807400112,
     "user_tz": 480,
     "elapsed": 7418,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "62f3f9a0-0152-4c74-c5dc-a9cc15137c90"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=4,                 # 超小 rank\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],  # 常見名稱；找不到時 PEFT 會自動跳過\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.print_trainable_parameters()  # 觀察可訓練參數比例"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1sWja8Ggmdb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762807411828,
     "user_tz": 480,
     "elapsed": 1046,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "cc43faaf-7594-44b3-b592-f35af6817dec"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "MAX_LEN = 256  # CPU 環境用較短序列，速度差很多\n",
    "\n",
    "def tok_fn(batch):\n",
    "    enc = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    enc[\"labels\"] = [ids[:] for ids in enc[\"input_ids\"]]\n",
    "    return enc\n",
    "\n",
    "tok_ds = train_ds.map(tok_fn, batched=True, remove_columns=train_ds.column_names)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "51320f35f7db4be2a272e367d4d31ca9",
      "6c4517d7601243c08b697287e98fdf3d",
      "0d5b927b6a954ad597d67fdfe4ae6314",
      "738fa2dc1a844e3d9654ee6ad08f7c51",
      "cdb9b2406ebd4b1d9110cf0df7077359",
      "d5a3a101efeb4614aacb21c7fa2a14a7",
      "3c5dc7bede494b108c4ebb1b09ba128e",
      "1d713a38637a46ed9517fffcde09d154",
      "46180c822d384c529165a84cda51dcee",
      "83071df584194cc280cc31bd6d120c44",
      "89b4ef8c03a845f5b66c638249cae636"
     ]
    },
    "id": "cP50fMV7gqfa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762807427671,
     "user_tz": 480,
     "elapsed": 315,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "81bcb58d-dc66-40f5-f285-3acb97d4339e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/content/lora_full_cpu_out\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,     # 等效 batch=8，但仍是 CPU 省記憶體\n",
    "    learning_rate=5e-4,                # LoRA 可略大\n",
    "    weight_decay=0.0,\n",
    "    max_steps=150,                     # 小步數（100–300 都可）；越多效果越好但越久\n",
    "    warmup_ratio=0.03,\n",
    "    logging_steps=10,\n",
    "    save_steps=75,\n",
    "    save_total_limit=1,\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_ds,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726
    },
    "id": "pyZP9R71gtUx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762809968435,
     "user_tz": 480,
     "elapsed": 2529799,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "08eefa8f-c724-4087-b8cf-91b8a9cb353b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "save_dir = \"/content/lora_smolm2_cpu\"\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(\"LoRA adapters saved to:\", save_dir)\n",
    "\n",
    "# （可選）把 LoRA 合併回基礎模型權重，輸出可直接推理的 safetensors\n",
    "# —— 合併會比較慢，CPU 可做但要等一下；不合併也能用 PEFT 加載推理。\n",
    "# from peft import merge_and_unload\n",
    "# merged = merge_and_unload(model)           # 合併 LoRA 到 base\n",
    "# merged.save_pretrained(\"/content/smolm2_lora_merged\", safe_serialization=True)\n",
    "# tokenizer.save_pretrained(\"/content/smolm2_lora_merged\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4i3Y1Ohuqdnq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762810001351,
     "user_tz": 480,
     "elapsed": 531,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "229fbbf4-0b76-4b65-e8e1-9bbf6b7d6801"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "model.eval()\n",
    "\n",
    "def chat(prompt, max_new_tokens=64, sample=False):\n",
    "    text = (\n",
    "        \"### Instruction:\\nYou are a helpful assistant. Answer briefly.\\n\\n\"\n",
    "        f\"### Input:\\n{prompt}\\n\\n### Response:\\n\"\n",
    "    )\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=sample,          # CPU 建議先關閉採樣，較穩定\n",
    "            temperature=0.7 if sample else None,\n",
    "            top_p=0.9 if sample else None,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    decoded = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    return decoded.split(\"### Response:\")[-1].strip()\n",
    "\n",
    "print(chat(\"Explain cross-validation in one sentence.\"))\n",
    "print(\"----\")\n",
    "print(chat(\"Give a short tip to avoid overfitting.\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZZ3YMuDqlXG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762810083013,
     "user_tz": 480,
     "elapsed": 54392,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "955d0ae5-cde0-4340-fa16-f5e91745f5cb"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}