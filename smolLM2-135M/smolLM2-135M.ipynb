{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNC9LyJ4+HcNTxFPVu/HRv8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJzijipVclw6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762749981152,
     "user_tz": 480,
     "elapsed": 96259,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "0de11807-d5cb-4239-d81f-b64f95f43fc2"
   },
   "outputs": [],
   "source": [
    "# 先清理可能干擾的套件（不存在也沒關係）\n",
    "!pip uninstall -y unsloth unsloth-zoo transformers accelerate datasets trl bitsandbytes \\\n",
    "  pyarrow fsspec gcsfs cudf-cu12 pylibcudf-cu12 dask-cudf-cu12 cuml-cu12 \\\n",
    "  sentence-transformers torchtune || true\n",
    "\n",
    "!pip install -U pip\n",
    "\n",
    "# 與 Colab 的 torch 2.8.0+cu126 相容的 triton\n",
    "!pip install triton==3.4.0\n",
    "\n",
    "# 核心組合（transformers 釘 4.55.2 → 修復 cached_property 錯）\n",
    "!pip install transformers==4.55.2 accelerate==1.4.0 datasets==4.3.0\n",
    "\n",
    "# datasets / 雲端 I/O 依賴（避免 bigframes/gcsfs 抱怨）\n",
    "!pip install pyarrow==21.0.0 fsspec==2024.5.0 gcsfs==2024.5.0\n",
    "\n",
    "# 與 unsloth 相容且非黑名單的 bitsandbytes 版本\n",
    "!pip install bitsandbytes==0.47.0\n",
    "\n",
    "# TRL（SFTTrainer）與 unsloth 本體 / zoo\n",
    "!pip install trl==0.23.0 unsloth==2025.11.2 unsloth-zoo==2025.11.3\n",
    "\n",
    "#（可選）避免 sentence-transformers 後續噪音\n",
    "!pip install sentence-transformers==5.1.2"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import unsloth  # 一定先 import，避免最佳化警告/相依順序問題\n",
    "import torch, transformers, datasets, accelerate, triton\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"triton:\", triton.__version__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"accelerate:\", accelerate.__version__)\n",
    "print(\"unsloth:\", unsloth.__version__)\n",
    "print(\"bitsandbytes:\", bnb.__version__)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "QVbIVIQWdRB9",
    "executionInfo": {
     "status": "error",
     "timestamp": 1762749997213,
     "user_tz": 480,
     "elapsed": 71,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "27d6d96a-b6df-457b-ac11-717197a8feb5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 產生一個迷你 chat 訓練集（Alpaca/指令式格式），確保流程能跑通\n",
    "import os, json\n",
    "os.makedirs(\"/content/data\", exist_ok=True)\n",
    "\n",
    "samples = [\n",
    "    {\"instruction\":\"You are a helpful assistant. Answer briefly.\",\n",
    "     \"input\":\"What is overfitting in machine learning?\",\n",
    "     \"output\":\"Overfitting is when a model learns training noise and performs poorly on new data.\"},\n",
    "    {\"instruction\":\"You are a helpful assistant. Answer briefly.\",\n",
    "     \"input\":\"Explain cross-validation in one sentence.\",\n",
    "     \"output\":\"Cross-validation splits data into folds to estimate generalization performance reliably.\"},\n",
    "    {\"instruction\":\"You are a helpful assistant. Answer briefly.\",\n",
    "     \"input\":\"What is the difference between classification and regression?\",\n",
    "     \"output\":\"Classification predicts discrete labels; regression predicts continuous values.\"},\n",
    "    {\"instruction\":\"You are a helpful assistant. Answer briefly.\",\n",
    "     \"input\":\"Give a short tip to avoid overfitting.\",\n",
    "     \"output\":\"Use more data, regularization, or validation-based early stopping.\"},\n",
    "    {\"instruction\":\"You are a helpful assistant. Answer briefly.\",\n",
    "     \"input\":\"Name one evaluation metric for binary classification.\",\n",
    "     \"output\":\"F1-score.\"},\n",
    "]\n",
    "with open(\"/content/data/chat_train.jsonl\", \"w\") as f:\n",
    "    for ex in samples:\n",
    "        f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 正確載入方式：key 是 split 名稱（不是檔名）\n",
    "from datasets import load_dataset\n",
    "ds_dict = load_dataset(\"json\", data_files={\"train\": \"/content/data/chat_train.jsonl\"})\n",
    "print(ds_dict)\n",
    "print(ds_dict[\"train\"][0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "ef64ee5460c14222a0048b3048159755",
      "0d753eca759843f4b96b5fd226ac90cb",
      "7d74a72940fd4b1d93ff30849641836f",
      "df6284c155e4480a94e0c775f82c3030",
      "f4ebfee1ec024a78a5acdc1de1ecf32a",
      "39647656424048d093eb46865ad8acaf",
      "b2ef3526aed248d592c67acecd200dc3",
      "6dad958146624a078e48da272989e7fa",
      "c4908fdd86fe43389cbc49c221af09bd",
      "65a84efe51c6471491df6bea3b0c7612",
      "30ce1229be7c4b219a51125d0b4d7b10"
     ]
    },
    "id": "vjhPeNmaeyqr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762750003906,
     "user_tz": 480,
     "elapsed": 4273,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "75281e87-1168-4b2a-f32e-217e345b903f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "BASE_MODEL = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "USE_BF16 = torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
    "TORCH_DTYPE = torch.bfloat16 if USE_BF16 else torch.float16\n",
    "\n",
    "print(\"Using dtype:\", TORCH_DTYPE)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "model = None; tokenizer = None\n",
    "try:\n",
    "    from unsloth import FastLanguageModel\n",
    "    print(\"✓ Using unsloth.FastLanguageModel\")\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = BASE_MODEL,\n",
    "        dtype      = TORCH_DTYPE,\n",
    "        load_in_4bit = False,          # Full finetuning：不用 4-bit\n",
    "        trust_remote_code = True,\n",
    "    )\n",
    "    # 啟用訓練（全參數）；不同 unsloth 版本 API 可能不同，做兼容\n",
    "    if hasattr(FastLanguageModel, \"for_training\"):\n",
    "        FastLanguageModel.for_training(model, use_gradient_checkpointing=True)\n",
    "    else:\n",
    "        model.gradient_checkpointing_enable()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"[INFO] unsloth 載入失敗，fallback 到 transformers。原因：\", e)\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL,\n",
    "        torch_dtype=TORCH_DTYPE,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "_ = model.to(\"cuda\")\n",
    "print(\"Model device:\", next(model.parameters()).device)\n",
    "print(\"Vocab size:\", len(tokenizer))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837,
     "referenced_widgets": [
      "6c73e271e0c84dcb9ec99bf111906a4b",
      "b75a0bf91ae740b7a1cde382997227d5",
      "334802d73ca34f38b867d200e097f1d9",
      "e79c002992f1474396a009a15552445c",
      "3112ba1d1256499094ea699dcd944ebc",
      "f206850582834b19a138392aacd2b473",
      "3a167cdba5604f75abd47d7a100ae704",
      "cd58aafdab0d4df284c136f41f03c286",
      "c77b1a12c56e473fb582536e7caf0931",
      "62b4d937f4f5473c9ee06ec5b45198fe",
      "384b6a6adde74446bfee97e3a6b8a411",
      "583d37023be840e481a340e95bb262a7",
      "29ce88628e64415a9e922732a2d1a2e0",
      "e6f11e2c2d7a4002bc6a72f64da4ef17",
      "97d54d1c2b354bcb9dfa5ec4f49c1c6a",
      "b68068d12cd14640a1f6b046d8c10d81",
      "0c4a7d56c2904475beb233c64a1176fb",
      "6b0def52351b4ffa880bff5939a900fd",
      "792399b8de4947f982e5e843deb24b38",
      "649830237ffb491590b2df5150c7fc14",
      "c76237fc6e8c4806bd5a6b92dd7c9039",
      "ce43a6c6e60c47cbad37df2c5ae15a7c",
      "b07acfaac47045b0967ae9e78f8ac2f0",
      "99ceb13a71e14e628de64283ac725f5e",
      "817ea103023b4cf18dfdabd91691ec1e",
      "6416da6b231741e6ac7fa5f36375ac28",
      "56906fa688b24bfebee51536436ef320",
      "f44def90be5349bf9649749525b462a8",
      "2a6dc89ae2c54a0d93c6cc286b52b0b6",
      "a476d404b9c24caaa9f88297dbac3150",
      "e4a3678155504340803e1ad7ae7596d0",
      "ec3dfff773ba4d8682cf67b21e4152a4",
      "719bc413514e46ee8586b4b987085c0d",
      "c9b6cb47b6de498ea0cbef0471bbcd33",
      "8804c4138d0a424c85a2a08cdfda3a79",
      "c8eee7c60afd4a2286901a20407a4d60",
      "4f6f10991dc24f1f999bb005624c685f",
      "34afc5343b35432ba6e1d181fa1e9b7f",
      "1b5c142c5d814e6babb22a6765ce62e7",
      "e3e70aba09cf4768bec188d18aed1d4c",
      "f7bc856e2c154029ba9d5e22ae7ff996",
      "fa80912a44114dc48e95863e9884a5e0",
      "d6cb2be4e1514a73b79bc7e81d1a38fc",
      "e1c9a1499aee4674b8ba87ab935f8321",
      "ab5665f659d243d6a06df43755ff2ca0",
      "fb02d63950754014abb026bd937c58e8",
      "16f191698ac2475280abd2858086dc63",
      "4b82ad45e528480298c3087ae4a04bc9",
      "445f011b90f84c778def75496e92022f",
      "d79e8272e981406abd1280821de6f9d9",
      "ab6d711198fd4a7b8e9ec68fe198405d",
      "c42b5e713b69411d8d7f99663c4dc36a",
      "e8670a7b20ed47448ecf890b6d3437ae",
      "4fe842abb2934960b1e95cb3bbc16b60",
      "7855d40dac68465fa074ca310c578526",
      "5f0f32067f86439aaa157f5595f0c101",
      "18c1595ced0e47aea6fac101a34d89a0",
      "028fb733990d4e25a63952c41d3f9826",
      "7d08fcf2742547d5bb67fbef6bb98bfb",
      "8186f6ad2f3f4c1b89f50505c76b6372",
      "3fd0f9a0282942c1a29cc184fb9a7e2c",
      "b0b66e47e0f44b8797d5346e1c67e45b",
      "257bba4ec6b4443fb4ec2fb0f573c8ff",
      "ae8d1fa373ba44d7869d4221f19361c3",
      "fd56ac0fd0194bd6ad4621d91fedbed0",
      "9d0ad289b1dc4a6794bb2b61d33e63bb",
      "0e5af8623ae146d5b7f9d3fd578fe4bf",
      "d2cb17b736d1411b85fdce35b25ba8ff",
      "58d08b264f6345b79a4526b0e54346ab",
      "6c65716fad924ecaa1467890d4c02b84",
      "1a19b4dca49e4392b46aaf31ac923485",
      "1efcab4b017b4d97be48f0ee1d4ab04c",
      "f8cdf83dd91a4b929503dfbce4db6b64",
      "b8b95c684b464530901268e059762baa",
      "7dbc68b918b6491ca5b6a151d7fea04a",
      "28a2d2d4f2f74274ac5ad68580731d10",
      "1edac5ee13ce4c11b619984d6258f35b",
      "3d348832613245d7a0f69b018c75f025",
      "680bb8a47268470da95311ddf58e8f1c",
      "2b44e0661c56410c843b7e22e565ef20",
      "0af5e1578c3f41c68e5df348e8af7c0a",
      "e3a8667212f14054ac1787db826171e2",
      "be7ba1c939fa4cb1a0f64cb83f759981",
      "1fc4e4b06d464661bd332bffa43046b5",
      "7aaccff789a04e4da50b57bcc746b74f",
      "9943211780f44338b9284011cbef4b3d",
      "8fd4a651c1284d4aa03656ea3f14278f",
      "97e2fa8ed2304c81970fb429ec72d95f"
     ]
    },
    "id": "uAoidDDke5La",
    "executionInfo": {
     "status": "error",
     "timestamp": 1762750049816,
     "user_tz": 480,
     "elapsed": 43415,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "9192a6bb-afd1-441a-e372-405087b813be"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds = ds_dict[\"train\"]\n",
    "\n",
    "def to_text(example):\n",
    "    instr = example.get(\"instruction\",\"\").strip()\n",
    "    inp   = example.get(\"input\",\"\").strip()\n",
    "    out   = example.get(\"output\",\"\").strip()\n",
    "    text = (\n",
    "        \"### Instruction:\\n\"\n",
    "        f\"{instr}\\n\\n\"\n",
    "        \"### Input:\\n\"\n",
    "        f\"{inp}\\n\\n\"\n",
    "        \"### Response:\\n\"\n",
    "        f\"{out}\"\n",
    "    )\n",
    "    return {\"text\": text}\n",
    "\n",
    "train_ds = train_ds.map(to_text, remove_columns=train_ds.column_names)\n",
    "print(train_ds[0][\"text\"])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192,
     "referenced_widgets": [
      "80096c15773b4eeb98e35563ad143a80",
      "305789e1b70a409ba5f54b89fe8f0283",
      "3882c84767894ffea696265ce3c73442",
      "dc4c1083954a4a16bdcac22a40fb45b5",
      "7615ff32ffbd4547902b6e2f164b2480",
      "a79feb5a1ef24be6ad77bba5750194cc",
      "4691ef30b64242089f3f6cef01c95420",
      "93345e0285874004885b20dc37f93c7d",
      "b3eb84b615444daeafe29640aad8ee18",
      "21547fcbdb6b42d28fe585871fa3fd62",
      "76df51659197458aaa06f788aacaf1af"
     ]
    },
    "id": "O7I_aRX4fGlD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762750077669,
     "user_tz": 480,
     "elapsed": 43,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "58750b41-ba71-49bc-db66-61b7fd0ee100"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# —— 完全關閉 AMP（避免 GradScaler 問題），FP32 最穩\n",
    "import os\n",
    "os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"no\"\n",
    "os.environ[\"DISABLE_MIXED_PRECISION\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "# 1) 將文字 tokenize（這次：不要回傳 tensor；留成 Python list）\n",
    "MAX_LEN = 512\n",
    "def tokenize_fn(batch):\n",
    "    enc = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=None,     # ← 關鍵：不要在這裡變成 tensor\n",
    "    )\n",
    "    # 自回歸 LM：labels = input_ids\n",
    "    enc[\"labels\"] = [ids[:] for ids in enc[\"input_ids\"]]\n",
    "    return enc\n",
    "\n",
    "tok_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=train_ds.column_names)\n",
    "\n",
    "# 2) DataLoader：在 collate 再把 list → torch.tensor\n",
    "def collate(batch):\n",
    "    # batch: List[Dict[str, list]]\n",
    "    keys = batch[0].keys()\n",
    "    out = {}\n",
    "    for k in keys:\n",
    "        arr = [b[k] for b in batch]  # List[list[int]]\n",
    "        # 有些欄位可能是 list（input_ids/labels/attention_mask）\n",
    "        # 統一轉成 LongTensor（常見做法；mask 也可 long）\n",
    "        out[k] = torch.tensor(arr, dtype=torch.long)\n",
    "    return out\n",
    "\n",
    "dl = DataLoader(tok_ds, batch_size=1, shuffle=True, collate_fn=collate, num_workers=0)\n",
    "\n",
    "# 3) Optimizer & Scheduler（FP32）\n",
    "optimizer = AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
    "num_epochs = 1\n",
    "num_update_steps_per_epoch = max(1, len(dl))\n",
    "max_train_steps = num_epochs * num_update_steps_per_epoch\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=max(1, int(0.03 * max_train_steps)),\n",
    "    num_training_steps=max_train_steps,\n",
    ")\n",
    "\n",
    "# 4) 極簡訓練迴圈（無 AMP、無 GradScaler）\n",
    "log_every = 5\n",
    "step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dl:\n",
    "        step += 1\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch.get(\"attention_mask\", None),\n",
    "            labels=batch[\"labels\"],\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if step % log_every == 0:\n",
    "            print(f\"epoch {epoch+1} step {step}/{max_train_steps} | loss = {loss.item():.4f}\")\n",
    "\n",
    "print(\"訓練完成 ✅\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "f10acc383ed6473584ff9ae0584a827f",
      "b7abe2ac25af4f5fa25fbd6c159d10ad",
      "365838812cc240ac8b78408aa3cf08c9",
      "09c25379afbf4aceae290b9a5501be8e",
      "97a1361d875640b0868b456214ced0af",
      "f2f71a7a6e404dd3ba4333615ad95973",
      "bfe83fc7751b4c7f8c10af57e27d3b9e",
      "d4abe4dadd3d4eb68cc1a09122a2df71",
      "2b5e0154930d4a6c8e331669e48c4071",
      "ac1c96960eb3459596be23c9b12f84f9",
      "fdd6f86ff61d40cda60437fd92a0e6d0"
     ]
    },
    "id": "sdXW5mdzij0v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762751576040,
     "user_tz": 480,
     "elapsed": 662090,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "d80a3d4c-72b6-4314-f669-7fa7b5bd4ca8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "save_dir = \"/content/smollm2_fullft_ckpt\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 儲存權重（含 config）；safe_serialization=True 會存成 .safetensors\n",
    "model.save_pretrained(save_dir, safe_serialization=True)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "# 檔案列表確認\n",
    "import glob\n",
    "print(\"Saved files:\", glob.glob(save_dir + \"/*\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NMuPjfTizYE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762751696154,
     "user_tz": 480,
     "elapsed": 6468,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "a1673747-2c80-4941-9c2d-8d98004b34b2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "model.eval()\n",
    "\n",
    "# 確保 tokenizer 有 pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 也同步到 model.config（有些模型在 generate 會讀這裡）\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def chat(prompt, max_new_tokens=96):\n",
    "    text = (\n",
    "        \"### Instruction:\\nYou are a helpful assistant. Answer briefly.\\n\\n\"\n",
    "        f\"### Input:\\n{prompt}\\n\\n### Response:\\n\"\n",
    "    )\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        # 重要：do_sample=False → 不走 multinomial，避免 \"probability tensor ...\" 錯誤\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,                # ← 改成貪婪解碼\n",
    "            temperature=None,               # 與 do_sample=False 搭配，避免軟化 logits\n",
    "            top_p=None,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    decoded = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    return decoded.split(\"### Response:\")[-1].strip()\n",
    "\n",
    "print(chat(\"Explain cross-validation in one sentence.\"))\n",
    "print(\"----\")\n",
    "print(chat(\"Give a short tip to avoid overfitting.\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYC52nzcQbGV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762753302919,
     "user_tz": 480,
     "elapsed": 17859,
     "user": {
      "displayName": "Yu Hsuan Lee",
      "userId": "05961625006192999823"
     }
    },
    "outputId": "5652bafe-b48c-4820-d0f6-89377d9378e0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 1) 上傳你要修的 .ipynb（選擇電腦或 Drive 下載下來的那個檔）\n",
    "from google.colab import files, output\n",
    "import json, os, io, sys\n",
    "\n",
    "uploaded = files.upload()\n",
    "assert uploaded, \"沒有選擇任何檔案\"\n",
    "src_name = list(uploaded.keys())[0]\n",
    "print(\"讀入：\", src_name)\n",
    "\n",
    "# 2) 嘗試解析 JSON（若壞檔會告知）\n",
    "try:\n",
    "    nb = json.loads(uploaded[src_name].decode(\"utf-8\"))\n",
    "except Exception as e:\n",
    "    print(\"❌ 檔案不是有效的 notebook JSON：\", e)\n",
    "    raise\n",
    "\n",
    "# 3) 進行安全清理：移除 metadata.widgets，並把每個 cell 內的 widgets 也移除\n",
    "meta = nb.setdefault(\"metadata\", {})\n",
    "if isinstance(meta.get(\"widgets\"), dict):\n",
    "    meta.pop(\"widgets\", None)\n",
    "\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if isinstance(cell.get(\"metadata\"), dict) and \"widgets\" in cell[\"metadata\"]:\n",
    "        cell[\"metadata\"].pop(\"widgets\", None)\n",
    "\n",
    "# （可選）也順便清掉所有輸出與執行次序，讓 GitHub/nbconvert 更穩\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        cell[\"outputs\"] = []\n",
    "        cell[\"execution_count\"] = None\n",
    "\n",
    "# 4) 另存為 *_clean.ipynb 並下載\n",
    "dst_name = os.path.splitext(src_name)[0] + \"_clean.ipynb\"\n",
    "with io.open(dst_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(nb, f, ensure_ascii=False, indent=1)\n",
    "print(\"✅ 產出：\", dst_name)\n",
    "\n",
    "files.download(dst_name)"
   ],
   "metadata": {
    "id": "aahhfGU0WAMp",
    "outputId": "2d139a1f-2e3e-48b3-82b1-ae1466953f43",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
